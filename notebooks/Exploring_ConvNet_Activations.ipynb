{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring ConvNet Activations\n",
    "\n",
    "[![Open In\n",
    "Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shaivimalik/covid_illegitimate_features/blob/main/notebooks/Exploring_ConvNet_Activations.ipynb)"
   ],
   "id": "a14f6ed4-ab00-447b-8fbe-2969a1f52a83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines if running on Google Colab\n",
    "#!git clone https://github.com/shaivimalik/covid_illegitimate_features.git\n",
    "#!pip install -r covid_illegitimate_features/requirements.txt\n",
    "#%cd covid_illegitimate_features/notebooks"
   ],
   "id": "20e3396c-e8ab-4c31-96dc-3d42ffb22b86"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from tensorflow import data as tf_data\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "keras.utils.set_random_seed(27)"
   ],
   "id": "17cbedbc-a4c0-4384-be2e-d29ed45d6034"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and batch size\n",
    "image_size = (256,256)\n",
    "batch_size = 4\n",
    "\n",
    "# Load training and validation sets from directory\n",
    "train_ds_leak, val_ds_leak= keras.utils.image_dataset_from_directory(\n",
    "    '../different_backgrounds/train', \n",
    "    label_mode=\"categorical\", \n",
    "    image_size=image_size, \n",
    "    batch_size=batch_size,\n",
    "    seed=27,\n",
    "    validation_split=0.125,\n",
    "    subset='both'\n",
    ")"
   ],
   "id": "39da2d5c-52e8-47a3-85b3-5192d6a3aff4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set from directory\n",
    "test_ds_leak= keras.utils.image_dataset_from_directory(\n",
    "    '../different_backgrounds/test', \n",
    "    label_mode=\"categorical\", \n",
    "    image_size=image_size, \n",
    "    batch_size=batch_size,\n",
    "    seed=27,\n",
    "    shuffle=False\n",
    ")"
   ],
   "id": "c8761fff-1026-4750-be2f-da566e6a153f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# Create model\n",
    "model_leak = keras.Sequential()\n",
    "\n",
    "# Add input layer\n",
    "model_leak.add(keras.Input(shape=image_size + (3,)))\n",
    "\n",
    "# Add rescaling layer to normalize pixel values\n",
    "model_leak.add(layers.Rescaling(scale=1./255))\n",
    "\n",
    "# Add convolutional and pooling layers\n",
    "model_leak.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"valid\", activation='relu', use_bias=True))\n",
    "model_leak.add(layers.MaxPooling2D(pool_size=(2, 2),padding=\"valid\"))\n",
    "model_leak.add(layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"valid\", activation='relu', use_bias=True))\n",
    "model_leak.add(layers.MaxPooling2D(pool_size=(2, 2),padding=\"valid\"))\n",
    "model_leak.add(layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"valid\", activation='relu', use_bias=True))\n",
    "model_leak.add(layers.MaxPooling2D(pool_size=(2, 2),padding=\"valid\"))\n",
    "\n",
    "# Flatten the output and add dense layers\n",
    "model_leak.add(layers.Flatten())\n",
    "model_leak.add(layers.Dense(64, activation='relu'))\n",
    "model_leak.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "model_leak.summary()"
   ],
   "id": "ca44a88c-e52f-4063-9562-3ac23ed0e498"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "# Compile the model\n",
    "model_leak.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history_leak = model_leak.fit(train_ds_leak, batch_size=batch_size, epochs=epochs, validation_data=val_ds_leak)"
   ],
   "id": "88822e83-e72d-48a2-b8c4-365aaa1dd03b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history_leak.history['accuracy'])\n",
    "plt.plot(history_leak.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_leak.history['loss'])\n",
    "plt.plot(history_leak.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ],
   "id": "0f8f0045-06f4-4032-8686-456e7df5be7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "score_leak = model_leak.evaluate(test_ds_leak)\n",
    "print(\"Test loss:\", score_leak[0])\n",
    "print(\"Test accuracy:\", score_leak[1])"
   ],
   "id": "563f92bf-7845-40a3-9289-10de118aed73"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_leak = model_leak.predict(test_ds_leak)\n",
    "y_pred_leak = np.argmax(y_pred_leak, axis=1)\n",
    "y_true_leak = np.concatenate([np.argmax(label, axis=1) for _, label in test_ds_leak], axis=0)\n",
    "conf_mat_leak = confusion_matrix(y_true_leak,y_pred_leak)\n",
    "ConfusionMatrixDisplay(conf_mat_leak,display_labels=['husky','wolf']).plot(cmap='Blues')"
   ],
   "id": "060a4b81-dc95-45d6-adf1-cb094285321b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "\n",
    "# Define image titles for visualization\n",
    "image_titles = ['husky', 'wolf']\n",
    "\n",
    "# Create lists of file paths for husky and wolf images\n",
    "husky_files = np.array(['../different_backgrounds/test/husky/'+x for x in os.listdir('../different_backgrounds/test/husky')])\n",
    "wolf_files = np.array(['../different_backgrounds/test/wolf/'+x for x in os.listdir('../different_backgrounds/test/wolf')])\n",
    "\n",
    "# Load random images for each class and convert them to a Numpy array\n",
    "husky = keras.utils.load_img(np.random.choice(husky_files), target_size=image_size)\n",
    "wolf = keras.utils.load_img(np.random.choice(wolf_files), target_size=image_size)\n",
    "images = np.asarray([np.array(husky), np.array(wolf)])\n",
    "X = np.array([keras.utils.img_to_array(img) for img in images])\n",
    "\n",
    "# Render the original images\n",
    "f, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "for i, title in enumerate(image_titles):\n",
    "    ax[i].set_title(title, fontsize=16)\n",
    "    ax[i].imshow(images[i])\n",
    "    ax[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define a function to modify the model for GradCAM\n",
    "def model_modifier_function(cloned_model):\n",
    "    cloned_model.layers[-1].activation = keras.activations.linear\n",
    "\n",
    "# Define a score function for GradCAM\n",
    "def score_function(output):\n",
    "    return (output[0,0], output[1,1])\n",
    "\n",
    "# Create Gradcam object\n",
    "gradcam = Gradcam(model_leak, model_modifier=model_modifier_function, clone=True)\n",
    "\n",
    "# Generate heatmap with GradCAM\n",
    "cam = gradcam(score_function, X)\n",
    "\n",
    "# Render the images with GradCAM heatmaps overlaid\n",
    "f, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "for i, title in enumerate(image_titles):\n",
    "    heatmap = np.uint8(cm.jet(cam[i])[..., :3] * 255)\n",
    "    ax[i].set_title(title, fontsize=16)\n",
    "    ax[i].imshow(images[i])\n",
    "    ax[i].imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "    ax[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "516c990d-e9f1-47e2-8142-b98c152b3882"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "background_swap = keras.utils.image_dataset_from_directory(\n",
    "    '../background_swap', \n",
    "    label_mode=\"categorical\", \n",
    "    image_size=image_size, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=27\n",
    ")\n",
    "score_swap = model_leak.evaluate(background_swap)\n",
    "print(\"Test loss:\", score_swap[0])\n",
    "print(\"Test accuracy:\", score_swap[1])"
   ],
   "id": "386a62dd-253e-4540-ad2e-191a15fef6af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_swap = model_leak.predict(background_swap)\n",
    "y_pred_swap = np.argmax(y_pred_swap, axis=1)\n",
    "y_true_swap = np.concatenate([np.argmax(label, axis=1) for _, label in background_swap], axis=0)\n",
    "conf_mat_swap = confusion_matrix(y_true_swap,y_pred_swap)\n",
    "ConfusionMatrixDisplay(conf_mat_swap,display_labels=['husky','wolf']).plot(cmap='Blues')"
   ],
   "id": "8cd1074a-c226-4680-ba8f-dffbf2e19a6d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and batch size\n",
    "image_size = (256,256)\n",
    "batch_size = 4\n",
    "\n",
    "# Load training and validation sets from directory\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    '../same_backgrounds/train', \n",
    "    label_mode=\"categorical\", \n",
    "    image_size=image_size, \n",
    "    batch_size=batch_size,\n",
    "    seed=27,\n",
    "    validation_split=0.125,\n",
    "    subset='both'\n",
    ")"
   ],
   "id": "6b16cade-ec96-4920-978a-891c8eb3aab8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set from directory\n",
    "test_ds= keras.utils.image_dataset_from_directory(\n",
    "    '../same_backgrounds/test', \n",
    "    label_mode=\"categorical\", \n",
    "    image_size=image_size, \n",
    "    batch_size=batch_size,\n",
    "    seed=17,\n",
    "    shuffle=False\n",
    ")"
   ],
   "id": "553b66e1-fd61-45f5-96c0-8042f08b91f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# Create the model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add input layer\n",
    "model.add(keras.Input(shape=image_size + (3,)))\n",
    "\n",
    "# Add rescaling layer to normalize pixel values\n",
    "model.add(layers.Rescaling(scale=1./255))\n",
    "\n",
    "# Add convolutional and pooling layers\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"valid\", activation='relu', use_bias=True))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2),padding=\"valid\"))\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"valid\", activation='relu', use_bias=True))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2),padding=\"valid\"))\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"valid\", activation='relu', use_bias=True))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2),padding=\"valid\"))\n",
    "\n",
    "# Flatten the output and add dense layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ],
   "id": "9ac885f5-a8bb-4eea-8140-d4df565c14ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_ds, batch_size=batch_size, epochs=epochs, validation_data=val_ds)"
   ],
   "id": "2e0d4435-a909-4bc2-af52-127551bcd23c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ],
   "id": "41286ab4-e158-4567-9461-1bc3442fb7b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "score = model.evaluate(test_ds)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ],
   "id": "969b67ac-efc1-4bc0-8f1b-e74647e74887"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_ds)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([np.argmax(label, axis=1) for _, label in test_ds], axis=0)\n",
    "conf_mat = confusion_matrix(y_true,y_pred)\n",
    "ConfusionMatrixDisplay(conf_mat,display_labels=['husky','wolf']).plot(cmap='Blues')"
   ],
   "id": "f1d0904c-b900-4c7c-86b3-a73a08124d77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "\n",
    "# Define image titles for visualization\n",
    "image_titles = ['husky', 'wolf']\n",
    "\n",
    "# Create lists of file paths for husky and wolf images\n",
    "husky_files = np.array(['../same_backgrounds/test/husky/'+x for x in os.listdir('../same_backgrounds/test/husky')])\n",
    "wolf_files = np.array(['../same_backgrounds/test/wolf/'+x for x in os.listdir('../same_backgrounds/test/wolf')])\n",
    "\n",
    "# Load random images for each class and convert them to a Numpy array\n",
    "husky = keras.utils.load_img(np.random.choice(husky_files), target_size=image_size)\n",
    "wolf = keras.utils.load_img(np.random.choice(wolf_files), target_size=image_size)\n",
    "images = np.asarray([np.array(husky), np.array(wolf)])\n",
    "X = np.array([keras.utils.img_to_array(img) for img in images])\n",
    "\n",
    "# Render the original images\n",
    "f, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "for i, title in enumerate(image_titles):\n",
    "    ax[i].set_title(title, fontsize=16)\n",
    "    ax[i].imshow(images[i])\n",
    "    ax[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define a function to modify the model for GradCAM\n",
    "def model_modifier_function(cloned_model):\n",
    "    cloned_model.layers[-1].activation = keras.activations.linear\n",
    "\n",
    "# Define a score function for GradCAM\n",
    "def score_function(output):\n",
    "    return (output[0,0], output[1,1])\n",
    "\n",
    "# Create Gradcam object\n",
    "gradcam = Gradcam(model, model_modifier=model_modifier_function, clone=True)\n",
    "\n",
    "# Generate heatmap with GradCAM\n",
    "cam = gradcam(score_function, X)\n",
    "\n",
    "# Render the images with GradCAM heatmaps overlaid\n",
    "f, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "for i, title in enumerate(image_titles):\n",
    "    heatmap = np.uint8(cm.jet(cam[i])[..., :3] * 255)\n",
    "    ax[i].set_title(title, fontsize=16)\n",
    "    ax[i].imshow(images[i])\n",
    "    ax[i].imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "    ax[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "8a17a2ec-5d5d-47af-9db5-df1d33bef84f"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
