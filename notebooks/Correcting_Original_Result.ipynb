{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing “Identification of COVID-19 samples from chest X-Ray images using deep learning: A comparison of transfer learning approaches” without Data Leakage\n",
    "\n",
    "[![Open In\n",
    "Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shaivimalik/covid_illegitimate_features/blob/main/notebooks/Correcting_Original_Result.ipynb)"
   ],
   "id": "fa172881-3140-4bca-a2ba-1d296e5340c4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ],
   "id": "e3c67f99-000e-4855-b82d-564001523b13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines if running on Google Colab\n",
    "#!git clone https://github.com/shaivimalik/covid_illegitimate_features.git\n",
    "#!pip install -r covid_illegitimate_features/requirements.txt\n",
    "#%cd covid_illegitimate_features/notebooks"
   ],
   "id": "44394ea6-a8a3-4e2c-9917-87612f8b1bf0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the datasets"
   ],
   "id": "4a634015-e1fe-4d5c-ab2d-3d11069e0f00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O images_01.tar.gz https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz\n",
    "!wget -O images_02.tar.gz https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz\n",
    "!wget -O images_03.tar.gz https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz\n",
    "!wget -O images_04.tar.gz https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz\n",
    "!wget -O images_05.tar.gz https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz\n",
    "!wget -O images_06.tar.gz https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz\n",
    "!wget -O images_07.tar.gz https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz\n",
    "!wget -O images_08.tar.gz https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz\n",
    "!wget -O images_09.tar.gz https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz\n",
    "!wget -O images_10.tar.gz https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz\n",
    "!wget -O images_11.tar.gz https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz\n",
    "!wget -O images_12.tar.gz https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz"
   ],
   "id": "19f72517-7765-4c0c-96bb-97a42ad47447"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir chest_xray\n",
    "\n",
    "!gunzip images_01.tar.gz\n",
    "!gunzip images_02.tar.gz\n",
    "!gunzip images_03.tar.gz\n",
    "!gunzip images_04.tar.gz\n",
    "!gunzip images_05.tar.gz\n",
    "!gunzip images_06.tar.gz\n",
    "!gunzip images_07.tar.gz\n",
    "!gunzip images_08.tar.gz\n",
    "!gunzip images_09.tar.gz\n",
    "!gunzip images_10.tar.gz\n",
    "!gunzip images_11.tar.gz\n",
    "!gunzip images_12.tar.gz\n",
    "\n",
    "!tar -xvf images_01.tar -C chest_xray\n",
    "!tar -xvf images_02.tar -C chest_xray\n",
    "!tar -xvf images_03.tar -C chest_xray\n",
    "!tar -xvf images_04.tar -C chest_xray\n",
    "!tar -xvf images_05.tar -C chest_xray\n",
    "!tar -xvf images_06.tar -C chest_xray\n",
    "!tar -xvf images_07.tar -C chest_xray\n",
    "!tar -xvf images_08.tar -C chest_xray\n",
    "!tar -xvf images_09.tar -C chest_xray\n",
    "!tar -xvf images_10.tar -C chest_xray\n",
    "!tar -xvf images_11.tar -C chest_xray\n",
    "!tar -xvf images_12.tar -C chest_xray"
   ],
   "id": "07ad4f77-39d3-4807-894c-f6319a9e08c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ieee8023/covid-chestxray-dataset.git"
   ],
   "id": "9da9ebfc-1052-4438-b487-5e8c56bf7941"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import data as tf_data\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras_cv import layers as layers_cv\n",
    "from keras.models import Model\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(20)\n",
    "tf.random.set_seed(20)"
   ],
   "id": "df7b95a7-eb47-4943-a528-552e039e61bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_files = os.listdir('covid-chestxray-dataset/images')\n",
    "df = pd.read_csv('covid-chestxray-dataset/metadata.csv')\n",
    "df = df[df['finding']=='Pneumonia/Viral/COVID-19']\n",
    "df = df[df['modality']=='X-ray']\n",
    "df = df[df['view']!='L']\n",
    "df.drop_duplicates(subset='patientid', keep='first', inplace=True)\n",
    "covid_files = df['filename'].to_list()\n",
    "covid_paths = np.random.choice(covid_files, size=260)\n",
    "covid_paths = ['covid-chestxray-dataset/images/' + i for i in covid_paths]"
   ],
   "id": "18c7a45a-55c2-4c02-a454-a2e8529b6765"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data_Entry_2017_v2020.csv')\n",
    "normal_paths = df[df['Finding Labels']=='No Finding'].sample(300)\n",
    "normal_paths = normal_paths['Image Index'].to_list()\n",
    "normal_paths = ['chest_xray/images/' + i for i in normal_paths]\n",
    "pneumonia_paths = df[df['Finding Labels']=='Pneumonia'].sample(300)\n",
    "pneumonia_paths = pneumonia_paths['Image Index'].to_list()\n",
    "pneumonia_paths = ['chest_xray/images/' + i for i in pneumonia_paths]"
   ],
   "id": "99f940c5-e851-4506-bb4e-9a9571d56b55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of COVID-19 samples:\", len(covid_paths))\n",
    "print(\"Number of Normal samples:\", len(normal_paths))\n",
    "print(\"Number of Pneumonia samples:\", len(pneumonia_paths))"
   ],
   "id": "ebf8ca57-87e7-408a-842d-b5f1e389e938"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_ds = tf.data.Dataset.from_tensor_slices(covid_paths)\n",
    "normal_ds = tf.data.Dataset.from_tensor_slices(normal_paths)\n",
    "pneumonia_ds = tf.data.Dataset.from_tensor_slices(pneumonia_paths)"
   ],
   "id": "84a22088-861e-4584-8a5d-62fef276086c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path, label):\n",
    "  # Load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  # Convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  # Resize the image to the desired size\n",
    "  img = tf.image.resize(img, [224, 224])\n",
    "  return img, label\n",
    "\n",
    "labels = {\"covid-19\":0, \"normal\":1, \"pneumonia\":2}\n",
    "covid_ds = covid_ds.map(lambda x: process_path(x,labels['covid-19']))\n",
    "normal_ds = normal_ds.map(lambda x: process_path(x,labels['normal']))\n",
    "pneumonia_ds = pneumonia_ds.map(lambda x: process_path(x,labels['pneumonia']))"
   ],
   "id": "41b7c240-7cd2-4f82-9d0c-ff4c339df11a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.load_img(covid_paths[5], color_mode='grayscale', target_size=(224,224))"
   ],
   "id": "8623b1ba-315b-4a2e-99ef-38796ec4ffb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.load_img(normal_paths[5], color_mode='grayscale', target_size=(224,224))"
   ],
   "id": "1f92f877-23c0-400c-bb11-aeb8ae87d91c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.load_img(pneumonia_paths[5], color_mode='grayscale', target_size=(224,224))"
   ],
   "id": "189337e2-07df-4cc2-b485-ea4405265521"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the convolutional neural network(VGG19) via Transfer Learning"
   ],
   "id": "5fb73403-c02d-44bb-b99f-1658c1675813"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting normal patients data acc. to stats given in paper\n",
    "normal_ds_train = normal_ds.take(200)\n",
    "normal_remaining = normal_ds.skip(200)\n",
    "normal_ds_val = normal_remaining.take(50)\n",
    "normal_ds_test = normal_remaining.skip(50)\n",
    "# Splitting pneumonia patients data acc. to stats given in paper\n",
    "pneumonia_ds_train = pneumonia_ds.take(200)\n",
    "pneumonia_remaining = pneumonia_ds.skip(200)\n",
    "pneumonia_ds_val = pneumonia_remaining.take(50)\n",
    "pneumonia_ds_test = pneumonia_remaining.skip(50)\n",
    "# Splitting covid patients data acc. to stats given in paper\n",
    "covid_ds_train = covid_ds.take(180)\n",
    "covid_remaining = covid_ds.skip(180)\n",
    "covid_ds_val = covid_remaining.take(40)\n",
    "covid_ds_test = covid_remaining.skip(40)"
   ],
   "id": "d3ed8145-c8eb-4630-a264-677da9f1f6b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (covid_ds_train.concatenate(normal_ds_train).concatenate(pneumonia_ds_train))\n",
    "validation_ds = (covid_ds_val.concatenate(normal_ds_val).concatenate(pneumonia_ds_val))\n",
    "test_ds = (covid_ds_test.concatenate(normal_ds_test).concatenate(pneumonia_ds_test))\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (keras.applications.vgg19.preprocess_input(x), y))\n",
    "validation_ds = validation_ds.map(lambda x, y: (keras.applications.vgg19.preprocess_input(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (keras.applications.vgg19.preprocess_input(x), y))"
   ],
   "id": "0cfd4300-87a5-46c4-b246-efa23268fadb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_layers = [\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "    layers_cv.RandomShear(x_factor=0.1, y_factor=0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "]\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))"
   ],
   "id": "7374fea3-67da-4083-b42e-65d47c244237"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n",
    "validation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n",
    "test_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()"
   ],
   "id": "fe02daa3-079f-4d7d-8a60-1c474f96b08d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG19(include_top=False, input_shape =[224, 224, 3], weights=\"imagenet\")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "predictions = layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.summary(show_trainable=True)"
   ],
   "id": "32e28786-b444-49d6-84f6-b1975ada4dab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(factor=0.3)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=validation_ds, callbacks=[reduce_lr])"
   ],
   "id": "af300237-8763-409a-9eb2-2c30519eaad3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "id": "cdfb3796-e996-4805-bc2f-56195207bad7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test accuracy :', accuracy)"
   ],
   "id": "90f9822a-31fe-468d-b6ea-9561af3bbbfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = model.predict(test_ds)\n",
    "# Convert predicted probabilities to class labels by taking the index of the highest probability\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(\"Predictions:\",y_pred)\n",
    "# Extract true labels from the test dataset\n",
    "y_true = tf.concat([label for _, label in test_ds], axis=0).numpy()\n",
    "print(\"True labels:\", y_true)"
   ],
   "id": "5c6d0ed5-e7ea-485b-8f6c-98430ddb65ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_mat = confusion_matrix(y_true,y_pred)\n",
    "# Display confusion matrix with labels\n",
    "ConfusionMatrixDisplay(conf_mat,display_labels=labels.keys()).plot(cmap='Blues')"
   ],
   "id": "8bb9a4fa-ea3f-4186-8c2a-74c50f365727"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "# Print metrics for each class\n",
    "for key in labels.keys():\n",
    "  print(\"class:\", key)\n",
    "  print(\"Precision:\",report[str(labels[key])]['precision'])\n",
    "  print(\"Recall:\",report[str(labels[key])]['recall'])\n",
    "  print(\"F1-score:\",report[str(labels[key])]['f1-score'])\n",
    "  print()"
   ],
   "id": "bd041b36-10f9-4d37-95ee-05691ac49cfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('correct_covid.keras')"
   ],
   "id": "79c14f81-74a0-4ad0-9d57-3a5e842d4051"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "|  Metric  | Original | Reproduced | Reproduced without Data Leakage |\n",
    "|:--------:|:--------:|:----------:|:-------------------------------:|\n",
    "| Accuracy |   89.3   |   92.14    |              51.43              |"
   ],
   "id": "8f751d24-a405-44e4-b6a1-96a2f27aa6b4"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
